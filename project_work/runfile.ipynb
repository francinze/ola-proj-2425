{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139cf2eb",
   "metadata": {},
   "source": [
    "# Project Requirements 2 & 3: Algorithm Comparison\n",
    "\n",
    "This notebook demonstrates the implementation of Project Requirements 2 and 3 using specialized seller classes:\n",
    "\n",
    "- **Requirement 2**: Multiple products + stochastic environment + Combinatorial-UCB\n",
    "- **Requirement 3**: Single product + best-of-both-worlds + Primal-Dual\n",
    "\n",
    "Both algorithms use the project-compliant binary demand model and corrected reward calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from base_classes.setting import Setting\n",
    "from base_classes.environment import Environment\n",
    "from base_classes.specialized_sellers import create_seller_for_requirement\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üìö Libraries imported and environment configured\")\n",
    "print(\"üéØ Ready to run Project Requirements 2 & 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42687669",
   "metadata": {},
   "source": [
    "## Requirement 2: Multiple Products + Combinatorial-UCB\n",
    "\n",
    "**Configuration:**\n",
    "- Multiple products (N=3)\n",
    "- Stochastic environment (stationary)\n",
    "- CombinatorialUCBSeller with inventory constraint\n",
    "- Discrete price set with 5 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ REQUIREMENT 2: Multiple products with Combinatorial-UCB\n",
    "print(\"üèóÔ∏è  REQUIREMENT 2: MULTIPLE PRODUCTS + COMBINATORIAL-UCB\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "req2_setting = Setting(\n",
    "    T=500,\n",
    "    n_products=3,  # Multiple products as required\n",
    "    epsilon=0.2,   # Discrete price set (5 levels)\n",
    "    distribution='gaussian',  # Stochastic environment\n",
    "    dist_params=(50, 15),     # Distribution parameters\n",
    "    verbose='no',\n",
    "    budget_constraint=\"strict\",  # Inventory constraint B\n",
    "    non_stationary='no',      # Stochastic (stationary)\n",
    "    algorithm=\"combinatorial_ucb\"\n",
    ")\n",
    "\n",
    "# Create environment with specialized seller\n",
    "req2_env = Environment(req2_setting)\n",
    "req2_env.seller = create_seller_for_requirement(2, req2_setting)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - Products: {req2_setting.n_products}\")\n",
    "print(f\"  - Price levels: {int(1/req2_setting.epsilon)}\")\n",
    "print(f\"  - Environment: Stochastic (stationary)\")\n",
    "print(f\"  - Seller: {req2_env.seller.__class__.__name__}\")\n",
    "print(f\"  - Budget constraint: {req2_setting.B:.2f}\")\n",
    "\n",
    "# Run experiment\n",
    "print(f\"\\nüöÄ Running Requirement 2 experiment...\")\n",
    "req2_env.play_all_rounds()\n",
    "\n",
    "# Calculate results\n",
    "req2_rewards = np.array(req2_env.seller.history_rewards)\n",
    "req2_regrets = req2_env.optimal_rewards - req2_rewards\n",
    "req2_cum_regret = np.cumsum(req2_regrets)\n",
    "\n",
    "print(f\"‚úÖ Requirement 2 completed!\")\n",
    "print(f\"   Final cumulative regret: {req2_cum_regret[-1]:.2f}\")\n",
    "print(f\"   Total rewards: {np.sum(req2_rewards):.2f}\")\n",
    "print(f\"   Efficiency: {(np.sum(req2_rewards)/np.sum(req2_env.optimal_rewards)*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c1a67",
   "metadata": {},
   "source": [
    "## Requirement 3: Single Product + Primal-Dual\n",
    "\n",
    "**Configuration:**\n",
    "- Single product (N=1)\n",
    "- Best-of-both-worlds: highly non-stationary environment\n",
    "- PrimalDualSeller with inventory constraint\n",
    "- Handles both stationary and adversarial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ REQUIREMENT 3: Single product with primal-dual for non-stationary\n",
    "print(\"üèóÔ∏è  REQUIREMENT 3: SINGLE PRODUCT + PRIMAL-DUAL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "req3_setting = Setting(\n",
    "    T=500,\n",
    "    n_products=1,  # Single product as required\n",
    "    epsilon=0.2,   # Discrete price set (5 levels)\n",
    "    distribution='gaussian',  # Stochastic base\n",
    "    dist_params=(50, 15),\n",
    "    verbose='no',\n",
    "    budget_constraint=\"strict\",  # Inventory constraint B\n",
    "    non_stationary='highly',  # Highly non-stationary environment\n",
    "    algorithm=\"primal_dual\"\n",
    ")\n",
    "\n",
    "# Create environment with specialized seller\n",
    "req3_env = Environment(req3_setting)\n",
    "req3_env.seller = create_seller_for_requirement(3, req3_setting)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - Products: {req3_setting.n_products} (single product)\")\n",
    "print(f\"  - Price levels: {int(1/req3_setting.epsilon)}\")\n",
    "print(f\"  - Environment: Highly non-stationary\")\n",
    "print(f\"  - Seller: {req3_env.seller.__class__.__name__}\")\n",
    "print(f\"  - Budget constraint: {req3_setting.B:.2f}\")\n",
    "\n",
    "# Run experiment\n",
    "print(f\"\\nüöÄ Running Requirement 3 experiment...\")\n",
    "req3_env.play_all_rounds()\n",
    "\n",
    "# Calculate results\n",
    "req3_rewards = np.array(req3_env.seller.history_rewards)\n",
    "req3_regrets = req3_env.optimal_rewards - req3_rewards\n",
    "req3_cum_regret = np.cumsum(req3_regrets)\n",
    "\n",
    "print(f\"‚úÖ Requirement 3 completed!\")\n",
    "print(f\"   Final cumulative regret: {req3_cum_regret[-1]:.2f}\")\n",
    "print(f\"   Total rewards: {np.sum(req3_rewards):.2f}\")\n",
    "print(f\"   Efficiency: {(np.sum(req3_rewards)/np.sum(req3_env.optimal_rewards)*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd767c3d",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Compare the performance of both algorithms in their respective optimal environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a306ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Performance Comparison\n",
    "print(\"üìä PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "req2_efficiency = (np.sum(req2_rewards) / np.sum(req2_env.optimal_rewards)) * 100\n",
    "req3_efficiency = (np.sum(req3_rewards) / np.sum(req3_env.optimal_rewards)) * 100\n",
    "\n",
    "print(f\"REQUIREMENT 2 (Multiple products + Combinatorial-UCB):\")\n",
    "print(f\"  Seller: {req2_env.seller.__class__.__name__}\")\n",
    "print(f\"  Final cumulative regret: {req2_cum_regret[-1]:.2f}\")\n",
    "print(f\"  Average regret per round: {req2_cum_regret[-1]/len(req2_cum_regret):.3f}\")\n",
    "print(f\"  Efficiency vs optimal: {req2_efficiency:.1f}%\")\n",
    "print(f\"  Expected behavior: Sublinear regret O(‚àöT log T)\")\n",
    "\n",
    "print(f\"\\nREQUIREMENT 3 (Single product + Primal-dual):\")\n",
    "print(f\"  Seller: {req3_env.seller.__class__.__name__}\")\n",
    "print(f\"  Final cumulative regret: {req3_cum_regret[-1]:.2f}\")\n",
    "print(f\"  Average regret per round: {req3_cum_regret[-1]/len(req3_cum_regret):.3f}\")\n",
    "print(f\"  Efficiency vs optimal: {req3_efficiency:.1f}%\")\n",
    "print(f\"  Expected behavior: Adaptive regret for non-stationary environments\")\n",
    "\n",
    "# Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Cumulative regret comparison\n",
    "ax1.plot(req2_cum_regret, label='Req 2: Combinatorial-UCB', color='blue', linewidth=2)\n",
    "ax1.plot(req3_cum_regret, label='Req 3: Primal-Dual', color='red', linewidth=2)\n",
    "ax1.set_xlabel('Round')\n",
    "ax1.set_ylabel('Cumulative Regret')\n",
    "ax1.set_title('Cumulative Regret Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Instantaneous regret (smoothed)\n",
    "window = 20\n",
    "req2_smooth = np.convolve(req2_regrets, np.ones(window)/window, mode='valid')\n",
    "req3_smooth = np.convolve(req3_regrets, np.ones(window)/window, mode='valid')\n",
    "\n",
    "ax2.plot(req2_smooth, label='Req 2: Combinatorial-UCB', color='blue', alpha=0.8)\n",
    "ax2.plot(req3_smooth, label='Req 3: Primal-Dual', color='red', alpha=0.8)\n",
    "ax2.set_xlabel('Round')\n",
    "ax2.set_ylabel('Instantaneous Regret (smoothed)')\n",
    "ax2.set_title(f'Smoothed Instantaneous Regret (window={window})')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Requirement 2 rewards\n",
    "ax3.plot(req2_rewards, label='Req 2 Rewards', color='blue', alpha=0.7)\n",
    "ax3.plot(req2_env.optimal_rewards, label='Req 2 Optimal', color='blue', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Round')\n",
    "ax3.set_ylabel('Reward')\n",
    "ax3.set_title('Requirement 2: Rewards vs Optimal')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Requirement 3 rewards\n",
    "ax4.plot(req3_rewards, label='Req 3 Rewards', color='red', alpha=0.7)\n",
    "ax4.plot(req3_env.optimal_rewards, label='Req 3 Optimal', color='red', linestyle='--', alpha=0.5)\n",
    "ax4.set_xlabel('Round')\n",
    "ax4.set_ylabel('Reward')\n",
    "ax4.set_title('Requirement 3: Rewards vs Optimal')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéØ PROJECT COMPLIANCE SUMMARY:\")\n",
    "print(f\"‚úÖ REQUIREMENT 2: Multiple products + Combinatorial-UCB (efficiency: {req2_efficiency:.1f}%)\")\n",
    "print(f\"‚úÖ REQUIREMENT 3: Single product + Primal-dual (efficiency: {req3_efficiency:.1f}%)\")\n",
    "print(f\"Both algorithms successfully implement their respective project requirements.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
